{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deputado Histogramado\n",
    "============\n",
    "\n",
    "[expressao.xyz/deputado/](http://expressao.xyz/deputado/)\n",
    "\n",
    "Como processar as sessões do parlamento Português"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Índice\n",
    "-----\n",
    "\n",
    "1. [Reunír o dataset](Deputado-Histogramado-1.ipynb)\n",
    "2. [Contando as palavras mais comuns](Deputado-Histogramado-2.ipynb)\n",
    "3. [Fazendo histogramas](Deputado-Histogramado-3.ipynb)\n",
    "4. [Representações geograficas](Deputado-Histogramado-4.ipynb)\n",
    "5. [Simplificar o dataset e exportar para o expressao.xyz/deputado/](Deputado-Histogramado-5.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O que se passou nas mais de 4000 sessões de discussão do parlamento Português que ocorreram desde 1976? \n",
    "Neste notebook vamos tentar visualizar o que se passou da maneira mais simples - contando palavras, e fazendo gráficos.\n",
    "\n",
    "Para obter os textos de todas as sessões usaremos o [demo.cratica.org](demo.cratica.org), onde podemos aceder facilmente a todas as sessões do parlamento de 1976 a 2015. Depois com um pouco de python, pandas e matplotlib vamos analisar o que se passou.\n",
    "\n",
    "Para executar estes notebook será necessário descarregar e abrir com o Jupiter Notebooks (a distribuição Anaconda faz com que instalar todas as ferramentas necessárias seja fácil - https://www.continuum.io/downloads)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3 - Simplificar o dataset e exportar\n",
    "Código para carregar os dados do notebook anterior: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pylab\n",
    "import matplotlib\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "\n",
    "dateparse = lambda x: pandas.datetime.strptime(x, '%Y-%m-%d')\n",
    "sessoes = pandas.read_csv('sessoes_democratica_org.csv',index_col=0,parse_dates=['data'], date_parser=dateparse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del sessoes['tamanho'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "799561050\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total0 = numpy.sum(sessoes['sessao'].map(len))\n",
    "print(total0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos ~800 MB de dados. O servidor onde o backend do site vai funcionar apenas têm 1GB de memória, o que cria um desafio técnico. Como a útilidade do site é apenas contar palavras ou expressões que ocorrem mais em certas sessões, e não em todas as sessões ('enfermeiro' vs 'deputado'), podemos retirar essas palavras mais usuais:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def substitui_palavras_comuns(texto):\n",
    "    t = texto.replace('.',' ').replace('\\n',' ').replace(',',' ').replace(')',' ').replace('(',' ').replace('!',' ').replace('?',' ').replace(':',' ').replace(';',' ')\n",
    "    t = t.replace(' de ',' ').replace(' que ',' ').replace(' do ',' ').replace(' da ',' ').replace(' sr ',' ').replace(' não ',' ').replace(' em ',' ').replace(' se ','').replace(' para',' ').replace(' os ',' ').replace(' dos ',' ').replace(' uma ',' ').replace(' um ',' ').replace(' as ',' ').replace(' dos ',' ').replace(' no ',' ').replace(' dos ',' ').replace('presidente','').replace(' na ',' ').replace(' por ','').replace('presidente','').replace(' com ',' ').replace(' ao ',' ').replace('deputado','').replace(' das ',' ').replace(' como ','').replace('governo','').replace(' ou ','').replace(' mais ',' ').replace(' assembleia ','').replace(' ser ',' ').replace(' tem ',' ')\n",
    "    t = t.replace(' srs ','').replace(' pelo ','').replace(' mas ','').replace(' foi ','').replace('srs.','').replace('palavra','').replace(' que ','').replace(' sua ','').replace(' artigo ','').replace(' nos ','').replace(' eu ','').replace('muito','').replace('sobre ','').replace('também','').replace('proposta','').replace(' aos ',' ').replace(' esta ',' ').replace(' já ',' ')\n",
    "    t = t.replace(' vamos ',' ').replace(' nesta ',' ').replace(' lhe ',' ').replace(' meu ',' ').replace(' eu ',' ').replace(' vai ',' ')\n",
    "    t = t.replace(' isso ',' ').replace(' dia ',' ').replace(' discussão ',' ').replace(' dizer ',' ').replace(' seus ',' ').replace(' apenas ',' ').replace(' agora ',' ')\n",
    "    t = t.replace(' ª ',' ').replace(' foram ',' ').replace(' pois ',' ').replace(' 
    ',' ').replace(' suas ',' ').replace(' deste ',' ').replace(' quer ',' ').replace(' desta ',' ').replace(' qual ',' ')\n",
    "    t = t.replace(' o ',' ').replace(' a ',' ').replace(' e ',' ').replace(' é ',' ').replace(' à ',' ').replace(' s ',' ')\n",
    "    t = t.replace(' - ','').replace(' º ',' ').replace(' n ',' ').replace(' . ',' ').replace(' são ',' ').replace(' está ',' ').replace(' seu ',' ').replace(' há ',' ').replace('orador',' ').replace(' este ',' ').replace(' pela ',' ').replace(' bem ',' ').replace(' nós ',' ').replace('porque','').replace('aqui','').replace(' às ',' ').replace('ainda','').replace('todos','').replace(' só ',' ').replace('fazer',' ').replace(' sem ',' ').replace(' qualquer ',' ').replace(' quanto ',' ').replace(' pode ',' ').replace(' nosso ',' ').replace(' neste ',' ').replace(' ter ',' ').replace(' mesmo ',' ').replace(' essa ',' ').replace(' até ',' ').replace(' me ',' ').replace(' nossa ',' ').replace(' entre ',' ').replace(' nas ',' ').replace(' esse ',' ').replace(' será ',' ').replace(' isto ',' ').replace(' quando ',' ').replace(' seja ',' ').replace(' assim ',' ').replace(' quanto ',' ').replace(' pode ',' ').replace(' é ',' ')\n",
    "    t = t.replace('  ',' ').replace('  ',' ').replace('  ',' ')\n",
    "    return t\n",
    "\n",
    "\n",
    "sessoes['sessao'] = sessoes['sessao'].map(substitui_palavras_comuns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Fazendo uma contagem ás palavras mais frequentes que ainda restam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6928 x José\n",
      "6283 x Ps\n",
      "6205 x Partido\n",
      "6156 x Manuel\n",
      "5939 x Cds\n",
      "5897 x António\n",
      "5831 x Trabalhadores\n",
      "5136 x Comissão\n",
      "5131 x Psd\n",
      "5130 x Pcp\n",
      "5108 x Lei\n",
      "4173 x Constituição\n",
      "3837 x Política\n",
      "3227 x Contra\n",
      "3219 x Moreira\n",
      "3154 x Estado\n",
      "2953 x País\n",
      "2940 x Carlos\n",
      "2923 x Costa\n",
      "2828 x Povo\n",
      "2751 x Vital\n",
      "2707 x Voto\n",
      "2590 x Votação\n",
      "2568 x Luís\n",
      "2530 x Parlamentar\n",
      "2444 x Direito\n",
      "2425 x Trabalho\n",
      "2423 x Português\n",
      "2378 x Udp\n",
      "2365 x Nacional\n",
      "2330 x República\n",
      "2329 x Portanto\n",
      "2274 x Decreto-Lei\n",
      "2271 x Problema\n",
      "2265 x Socialista\n",
      "2264 x Ordem\n",
      "2260 x Nunes\n",
      "2241 x Social\n",
      "2236 x Portugal\n",
      "2226 x Parte\n",
      "2206 x Sentido\n",
      "2201 x Grupo\n",
      "2190 x Francisco\n",
      "2168 x Caso\n",
      "2145 x Regimento\n",
      "2102 x Outros\n",
      "2086 x Programa\n",
      "2082 x Mesa\n",
      "2066 x Carvalho\n",
      "2065 x Plano\n",
      "2063 x Ministro\n",
      "2055 x Facto\n",
      "2046 x Projecto\n",
      "2024 x Silva\n",
      "2020 x Seguinte\n",
      "2005 x Sessão\n",
      "2002 x Esclarecimento\n",
      "1992 x Relação\n",
      "1989 x Intervenção\n",
      "1944 x Era\n",
      "1942 x Tempo\n",
      "1913 x Antes\n",
      "1909 x Lugar\n",
      "1900 x Vozes\n",
      "1891 x Têm\n",
      "1887 x Questão\n",
      "1884 x Outro\n",
      "1865 x Forma\n",
      "1850 x Sousa\n",
      "1849 x Pelos\n",
      "1846 x Democracia\n",
      "1836 x Matéria\n",
      "1828 x Almeida\n",
      "1828 x Estão\n",
      "1815 x Sido\n",
      "1811 x Pereira\n",
      "1800 x Debate\n",
      "1797 x Medidas\n",
      "1795 x Poder\n",
      "1784 x Momento\n",
      "1757 x Vez\n",
      "1737 x Maria\n",
      "1728 x Conselho\n",
      "1726 x Situação\n",
      "1718 x Hoje\n",
      "1694 x Dias\n",
      "1686 x Partidos\n",
      "1673 x Ele\n",
      "1672 x Oliveira\n",
      "1667 x 25\n",
      "1663 x João\n",
      "1656 x Pedido\n",
      "1638 x Jorge\n",
      "1626 x Correia\n",
      "1618 x Favor\n",
      "1614 x Aplausos\n",
      "1613 x Acácio\n",
      "1600 x Alguns\n",
      "1589 x Horas\n",
      "1588 x Termos\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def agrupa_palavras(texto):\n",
    "    texto = texto.lower() #processa tudo em minusculas\n",
    "    palavras = re.split(';|,|\\n| |\\(|\\)|\\?|\\!|:',texto)   # separa as palavras\n",
    "    palavras = [x.title() for x in palavras if len(x)>0] # organiza e remove as palavras com menos de 5 caracteres\n",
    "    return palavras\n",
    "\n",
    "def conta_palavras(sessoes):\n",
    "    lista = sessoes['sessao'].map(agrupa_palavras)  # cria uma lista de 'lista de palavras', um elemento por sessao\n",
    "    palavras = []\n",
    "    for l in lista:\n",
    "        palavras.extend(l)                          # junta as 'listas de palavras' todas na mesma lista\n",
    "    return Counter(palavras).most_common(100)        # conta as palavras mais frequentes\n",
    "\n",
    "x = conta_palavras(sessoes[1:100])\n",
    "for (y,z) in x:\n",
    "    print(str(str(z)+' x '+y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "E estimando a redução de tamanho:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.03995185858541 %\n",
      "536025343\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total = numpy.sum(sessoes['sessao'].map(len))\n",
    "print(str(total/total0*100)+' %')\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "536 MB. Nada mau. Graças a esta redução tornou-se possível fazer uma query do site funcionar em ~4 seg em vez de 30 seg pois agora os dados cabem na memória. De notar que a ordem das palavras é a mesma, mas geram-se alguns problemas contando certas expressões ('porto de mar' é agora 'porto mar', e contando 'porto mar' tambem se contam ocorrencias de '(...)Porto. Mar(...)', pois retiramos os pontos e reduzimos os espaços consecutivos a um único. Mesmo assim, o dataset é perfeitamente útil para identificar em que sessões se falou de um certo assunto.\n",
    "\n",
    "Exportemos entao o ficheiro CSV que vai ser usado no site:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sessoes.to_csv('sessoes_democratica_clipped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
